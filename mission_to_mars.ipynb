{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "from urllib.parse import urlencode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=True)\n",
    "mars_data={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoup(url_to_get):\n",
    "    url=url_to_get\n",
    "    try:\n",
    "        browser.visit(url)\n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "        print(\"Scraping \"+url)\n",
    "        #print(len(html))\n",
    "        return soup\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect the latest News Title and Paragraph Text\n",
    "thisSoup=getSoup(\"https://mars.nasa.gov/news/\")\n",
    "\n",
    "with open('outfile.txt', 'w') as outfile:\n",
    "    outfile.write(thisSoup.text)\n",
    "    \n",
    "if len(thisSoup) !=1:\n",
    "    news_title = thisSoup.find('li', class_='slide').find('a').find('h3').text\n",
    "    \n",
    "    news_paragraph=thisSoup.find('li', class_='slide').find('div', class_=\"article_teaser_body\").text\n",
    "    mars_data[\"news_title\"]=news_title\n",
    "    mars_data[\"news_paragraph\"]=news_paragraph\n",
    "else:\n",
    "    mars_data[\"news_title\"]=\"unavailable\"\n",
    "    mars_data[\"news_paragraph\"]=\"unavailable\"\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Visit the url for JPL Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "#find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "thisUrl=\"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "thisSoup=getSoup(thisUrl)\n",
    "if len(thisSoup) !=1:\n",
    "    featured_img=thisSoup.find('section',class_='centered_text clearfix main_feature primary_media_feature single').find('article',class_=\"carousel_item\")\n",
    "    featured_img_url=featured_img.get('style')\n",
    "    featured_img_url=thisUrl[:24]+featured_img_url[23:-3]\n",
    "    mars_data[\"featured_img_url\"]=featured_img_url\n",
    "else:\n",
    "    mars_data[\"featured_img_url\"]=\"unavailable\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called `mars_weather`.\n",
    "thisSoup=getSoup(\"https://twitter.com/marswxreport?lang=en\")\n",
    "if thisSoup !=-1:\n",
    "    for div in thisSoup.find_all('div',attrs={'data-name':'Mars Weather'}):\n",
    "        tweet= div.find('p', class_='tweet-text')\n",
    "        if tweet and tweet.text.find('Sol ')!= -1:\n",
    "            mars_weather= tweet.text.strip().replace('\\n',' ')            \n",
    "            mars_weather=mars_weather[:mars_weather.find(\"pic\")]\n",
    "            break\n",
    "    mars_data[\"mars_weather\"]=mars_weather\n",
    "else:\n",
    "    mars_data[\"mars_weather\"]=\"unavailable\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mars_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Visit the Mars Facts webpage [here](http://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "#* Use Pandas to convert the data to a HTML table string.\n",
    "\n",
    "table_df=pd.read_html(\"http://space-facts.com/mars/\")\n",
    "df=table_df[0]\n",
    "df.columns=[\"Fact\",\"Value\"]\n",
    "df.columns.index=[\"Fact\"]\n",
    "htmlStr=df.to_html\n",
    "if htmlStr:\n",
    "    mars_data[\"facts\"]=htmlStr\n",
    "else:\n",
    "    mars_data[\"facts\"]=\"unavailable\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(mars_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Mars Hemispheres\n",
    "#* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "thisSoup=getSoup(\"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\")\n",
    "if thisSoup!=-1:\n",
    "    enh_img=thisSoup.find('div', class_='downloads').find('a')\n",
    "else:\n",
    "    print(\"error getting soup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click each of the links to the hemispheres in order to find the image url to the full resolution image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

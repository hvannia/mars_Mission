{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "from urllib.parse import urlencode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=True)\n",
    "mars_data={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoup(url_to_get):\n",
    "    url=url_to_get\n",
    "    try:\n",
    "        browser.visit(url)\n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "        print(\"Scraping \"+url)\n",
    "        #print(len(html))\n",
    "        return soup\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Reference\n",
    "try:\n",
    "    r = requests.get(url, params={'s': thing})\n",
    "except requests.exceptions.Timeout:\n",
    "    # Maybe set up for a retry, or continue in a retry loop\n",
    "except requests.exceptions.TooManyRedirects:\n",
    "    # Tell the user their URL was bad and try a different one\n",
    "except requests.exceptions.RequestException as e:\n",
    "    # catastrophic error. bail.\n",
    "    print e\n",
    "    sys.exit(1)\n",
    "    \n",
    "    \n",
    "with open('outfile.txt', 'w') as outfile:\n",
    "    outfile.write(thisSoup)\n",
    "print (type(thisSoup)) \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://mars.nasa.gov/news/\n"
     ]
    }
   ],
   "source": [
    "#collect the latest News Title and Paragraph Text\n",
    "thisSoup=getSoup(\"https://mars.nasa.gov/news/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(thisSoup) !=-1:\n",
    "    news_title = thisSoup.find('li', class_='slide').find('a').find('h3').text\n",
    "    \n",
    "    news_paragraph=thisSoup.find('li', class_='slide').find('div', class_=\"article_teaser_body\").text\n",
    "    mars_data[\"news_title\"]=news_title\n",
    "    mars_data[\"news_paragraph\"]=news_paragraph\n",
    "else:\n",
    "    mars_data[\"news_title\"]=\"unavailable\"\n",
    "    mars_data[\"news_paragraph\"]=\"unavailable\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_title': 'NASA to Share Results of Effort to Recover Mars Rover', 'news_paragraph': 'NASA will discuss the status of its Mars Exploration Rover Opportunity in a media briefing at 11 a.m. PST (2 p.m. EST) Wednesday, Feb. 13, from the Jet Propulsion Laboratory.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(mars_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\n"
     ]
    }
   ],
   "source": [
    "#* Visit the url for JPL Featured Space Image [here](https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars).\n",
    "#find the image url for the current Featured Mars Image and assign the url string to a variable called `featured_image_url`.\n",
    "thisUrl=\"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "thisSoup=getSoup(thisUrl)\n",
    "if len(thisSoup) !=1:\n",
    "    featured_img=thisSoup.find('section',class_='centered_text clearfix main_feature primary_media_feature single').find('article',class_=\"carousel_item\")\n",
    "    featured_img_url=featured_img.get('style')\n",
    "    featured_img_url=thisUrl[:24]+featured_img_url[23:-3]\n",
    "    mars_data[\"featured_img_url\"]=featured_img_url\n",
    "else:\n",
    "    mars_data[\"featured_img_url\"]=\"unavailable\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_title': 'NASA to Share Results of Effort to Recover Mars Rover', 'news_paragraph': 'NASA will discuss the status of its Mars Exploration Rover Opportunity in a media briefing at 11 a.m. PST (2 p.m. EST) Wednesday, Feb. 13, from the Jet Propulsion Laboratory.', 'featured_img_url': 'https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA17440-1920x1200.jpg'}\n"
     ]
    }
   ],
   "source": [
    "print(mars_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://twitter.com/marswxreport?lang=en\n"
     ]
    }
   ],
   "source": [
    "#* Visit the Mars Weather twitter account [here](https://twitter.com/marswxreport?lang=en) and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called `mars_weather`.\n",
    "thisSoup=getSoup(\"https://twitter.com/marswxreport?lang=en\")\n",
    "if thisSoup !=-1:\n",
    "    for div in thisSoup.find_all('div',attrs={'data-name':'Mars Weather'}):\n",
    "        tweet= div.find('p', class_='tweet-text')\n",
    "        if tweet and tweet.text.find('Sol ')!= -1:\n",
    "            mars_weather= tweet.text.strip().replace('\\n',' ')            \n",
    "            mars_weather=mars_weather[:mars_weather.find(\"pic\")]\n",
    "            break\n",
    "    mars_data[\"mars_weather\"]=mars_weather\n",
    "else:\n",
    "    mars_data[\"mars_weather\"]=\"unavailable\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_title': 'NASA to Share Results of Effort to Recover Mars Rover', 'news_paragraph': 'NASA will discuss the status of its Mars Exploration Rover Opportunity in a media briefing at 11 a.m. PST (2 p.m. EST) Wednesday, Feb. 13, from the Jet Propulsion Laboratory.', 'featured_img_url': 'https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA17440-1920x1200.jpg', 'mars_weather': 'Sol 2315 (2019-02-09), high -17C/1F, low -71C/-95F, pressure at 8.13 hPa, daylight 06:47-18:52'}\n"
     ]
    }
   ],
   "source": [
    "print(mars_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Visit the Mars Facts webpage [here](http://space-facts.com/mars/) and use Pandas to scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "#* Use Pandas to convert the data to a HTML table string.\n",
    "\n",
    "table_df=pd.read_html(\"http://space-facts.com/mars/\")\n",
    "df=table_df[0]\n",
    "df.columns=[\"Fact\",\"Value\"]\n",
    "df.columns.index=[\"Fact\"]\n",
    "htmlStr=df.to_html\n",
    "if htmlStr:\n",
    "    mars_data[\"facts\"]=htmlStr\n",
    "else:\n",
    "    mars_data[\"facts\"]=\"unavailable\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'news_title': 'NASA to Share Results of Effort to Recover Mars Rover', 'news_paragraph': 'NASA will discuss the status of its Mars Exploration Rover Opportunity in a media briefing at 11 a.m. PST (2 p.m. EST) Wednesday, Feb. 13, from the Jet Propulsion Laboratory.', 'featured_img_url': 'https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA17440-1920x1200.jpg', 'mars_weather': 'Sol 2315 (2019-02-09), high -17C/1F, low -71C/-95F, pressure at 8.13 hPa, daylight 06:47-18:52', 'facts': <bound method DataFrame.to_html of                    Fact                          Value\n",
      "0  Equatorial Diameter:                       6,792 km\n",
      "1       Polar Diameter:                       6,752 km\n",
      "2                 Mass:  6.42 x 10^23 kg (10.7% Earth)\n",
      "3                Moons:            2 (Phobos & Deimos)\n",
      "4       Orbit Distance:       227,943,824 km (1.52 AU)\n",
      "5         Orbit Period:           687 days (1.9 years)\n",
      "6  Surface Temperature:                  -153 to 20 Â°C\n",
      "7         First Record:              2nd millennium BC\n",
      "8          Recorded By:           Egyptian astronomers>}\n"
     ]
    }
   ],
   "source": [
    "print(mars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7e62f422dc93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mthisSoup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthisSoup\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0menh_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthisSoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'downloads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"error getting soup\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "### Mars Hemispheres\n",
    "#* Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "thisSoup=getSoup(\"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\")\n",
    "if thisSoup!=-1:\n",
    "    enh_img=thisSoup.find('div', class_='downloads').find('a')\n",
    "else:\n",
    "    print(\"error getting soup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click each of the links to the hemispheres in order to find the image url to the full resolution image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys `img_url` and `title`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "from urllib.parse import urlencode \n",
    "\n",
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=True)\n",
    "mars_data={}\n",
    "hemisphere_image_urls=[]\n",
    "\n",
    "def getSoup(url_to_get):\n",
    "    url=url_to_get\n",
    "    try:\n",
    "        browser.visit(url)\n",
    "        html = browser.html\n",
    "        soup = bs(html, \"html.parser\")\n",
    "        print(\"Scraping \"+url)\n",
    "        #print(len(html))\n",
    "        return soup\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getNews():\n",
    "    #collect the latest News Title and Paragraph Text\n",
    "    thisSoup=getSoup(\"https://mars.nasa.gov/news/\")\n",
    "    if len(thisSoup) !=-1:\n",
    "        news_title = thisSoup.find('li', class_='slide').find('a').find('h3').text\n",
    "        news_paragraph=thisSoup.find('li', class_='slide').find('div', class_=\"article_teaser_body\").text\n",
    "        mars_data[\"news_title\"]=news_title\n",
    "        mars_data[\"news_paragraph\"]=news_paragraph\n",
    "    else:\n",
    "        mars_data[\"news_title\"]=\"unavailable\"\n",
    "        mars_data[\"news_paragraph\"]=\"unavailable\"\n",
    "\n",
    "\n",
    "def getFeaturedImg():\n",
    "    thisUrl=\"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    thisSoup=getSoup(thisUrl)\n",
    "    if len(thisSoup) !=1:\n",
    "        featured_img=thisSoup.find('section',class_='centered_text clearfix main_feature primary_media_feature single').find('article',class_=\"carousel_item\")\n",
    "        featured_img_url=featured_img.get('style')\n",
    "        featured_img_url=thisUrl[:24]+featured_img_url[23:-3]\n",
    "        mars_data[\"featured_img_url\"]=featured_img_url\n",
    "    else:\n",
    "        mars_data[\"featured_img_url\"]=\"unavailable\"\n",
    "\n",
    "def getWeather():\n",
    "    thisSoup=getSoup(\"https://twitter.com/marswxreport?lang=en\")\n",
    "    if thisSoup !=-1:\n",
    "        for div in thisSoup.find_all('div',attrs={'data-name':'Mars Weather'}):\n",
    "            tweet= div.find('p', class_='tweet-text')\n",
    "            if tweet and tweet.text.find('Sol ')!= -1:\n",
    "                mars_weather= tweet.text.strip().replace('\\n',' ')            \n",
    "                mars_weather=mars_weather[:mars_weather.find(\"pic\")]\n",
    "                break\n",
    "        mars_data[\"mars_weather\"]=mars_weather\n",
    "    else:\n",
    "        mars_data[\"mars_weather\"]=\"unavailable\"\n",
    "\n",
    "def getFacts():\n",
    "    table_df=pd.read_html(\"http://space-facts.com/mars/\")\n",
    "    df=table_df[0]\n",
    "    df.columns=[\"Fact\",\"Value\"]\n",
    "    df.columns.index=[\"Fact\"]\n",
    "    htmlStr=df.to_html\n",
    "    if htmlStr:\n",
    "        mars_data[\"facts\"]=htmlStr\n",
    "    else:\n",
    "        mars_data[\"facts\"]=\"unavailable\"\n",
    "\n",
    "def hemispheres():\n",
    "    hemispheresUrls=[]\n",
    "    base_url=\"https://astrogeology.usgs.gov\"\n",
    "    thisSoup=getSoup(\"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\")\n",
    "    if thisSoup!=-1:\n",
    "        items=thisSoup.find_all('div', class_='item')\n",
    "        for i in items: \n",
    "            alls=i.find_all('a', class_='itemLink product-item') \n",
    "            for a in alls:\n",
    "                hemispheresUrls.append(a.get('href'))\n",
    "        unurls=set(hemispheresUrls)    # get unique list of urls, one for each hemisphere\n",
    "        for u in unurls: \n",
    "            #hemispheresUrls.append(base_url+u)\n",
    "            htitle= str.title(u[25:].replace('_',' '))\n",
    "            hemisurl=base_url+u\n",
    "            hemisSoup=getSoup(hemisurl)\n",
    "            hemislink=hemisSoup.find('div', class_=\"wide-image-wrapper \").find_all('a')[1].get('href')\n",
    "            hemispheres={} #clear\n",
    "            hemispheres['title']=htitle\n",
    "            hemispheres['img_url']=hemislink\n",
    "            hemisphere_image_urls.append(hemispheres)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
